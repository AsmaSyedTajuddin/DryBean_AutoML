{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325c7430",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-06T02:32:15.879327Z",
     "iopub.status.busy": "2022-05-06T02:32:15.878790Z",
     "iopub.status.idle": "2022-05-06T02:32:15.903767Z",
     "shell.execute_reply": "2022-05-06T02:32:15.903013Z"
    },
    "papermill": {
     "duration": 0.05209,
     "end_time": "2022-05-06T02:32:15.906355",
     "exception": false,
     "start_time": "2022-05-06T02:32:15.854265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dry-bean-dataset/Dry_Bean_Dataset/Dry_Bean_Dataset_Citation_Request.txt\n",
      "/kaggle/input/dry-bean-dataset/Dry_Bean_Dataset/Dry_Bean_Dataset.xlsx\n",
      "/kaggle/input/dry-bean-dataset/Dry_Bean_Dataset/Dry_Bean_Dataset.arff\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c620984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:32:15.941802Z",
     "iopub.status.busy": "2022-05-06T02:32:15.941012Z",
     "iopub.status.idle": "2022-05-06T02:32:57.372757Z",
     "shell.execute_reply": "2022-05-06T02:32:57.371938Z"
    },
    "papermill": {
     "duration": 41.453253,
     "end_time": "2022-05-06T02:32:57.374947",
     "exception": false,
     "start_time": "2022-05-06T02:32:15.921694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\r\n",
      "  Downloading openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting et-xmlfile\r\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\r\n",
      "Installing collected packages: et-xmlfile, openpyxl\r\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting flaml\r\n",
      "  Downloading FLAML-1.0.1-py3-none-any.whl (157 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 KB\u001b[0m \u001b[31m971.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: NumPy>=1.16.2 in /opt/conda/lib/python3.7/site-packages (from flaml) (1.21.6)\r\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in /opt/conda/lib/python3.7/site-packages (from flaml) (3.3.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /opt/conda/lib/python3.7/site-packages (from flaml) (1.0.2)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from flaml) (1.7.3)\r\n",
      "Collecting xgboost<=1.3.3,>=0.90\r\n",
      "  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.5/157.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.7/site-packages (from flaml) (1.3.5)\r\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm>=2.3.1->flaml) (0.37.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.4->flaml) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.4->flaml) (2021.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.24->flaml) (3.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.24->flaml) (1.0.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->flaml) (1.16.0)\r\n",
      "Installing collected packages: xgboost, flaml\r\n",
      "  Attempting uninstall: xgboost\r\n",
      "    Found existing installation: xgboost 1.6.0\r\n",
      "    Uninstalling xgboost-1.6.0:\r\n",
      "      Successfully uninstalled xgboost-1.6.0\r\n",
      "Successfully installed flaml-1.0.1 xgboost-1.3.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "!pip install flaml\n",
    "\n",
    "from flaml import AutoML\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec0f08a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:32:57.502600Z",
     "iopub.status.busy": "2022-05-06T02:32:57.502091Z",
     "iopub.status.idle": "2022-05-06T02:33:01.768612Z",
     "shell.execute_reply": "2022-05-06T02:33:01.767661Z"
    },
    "papermill": {
     "duration": 4.32725,
     "end_time": "2022-05-06T02:33:01.770675",
     "exception": false,
     "start_time": "2022-05-06T02:32:57.443425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28395</td>\n",
       "      <td>610.291</td>\n",
       "      <td>208.178117</td>\n",
       "      <td>173.888747</td>\n",
       "      <td>1.197191</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.141097</td>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28734</td>\n",
       "      <td>638.018</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.272750</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29380</td>\n",
       "      <td>624.110</td>\n",
       "      <td>212.826130</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30008</td>\n",
       "      <td>645.884</td>\n",
       "      <td>210.557999</td>\n",
       "      <td>182.516516</td>\n",
       "      <td>1.153638</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.467062</td>\n",
       "      <td>0.782681</td>\n",
       "      <td>0.976696</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30140</td>\n",
       "      <td>620.134</td>\n",
       "      <td>201.847882</td>\n",
       "      <td>190.279279</td>\n",
       "      <td>1.060798</td>\n",
       "      <td>0.333680</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.896503</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13606</th>\n",
       "      <td>42097</td>\n",
       "      <td>759.696</td>\n",
       "      <td>288.721612</td>\n",
       "      <td>185.944705</td>\n",
       "      <td>1.552728</td>\n",
       "      <td>0.765002</td>\n",
       "      <td>42508</td>\n",
       "      <td>231.515799</td>\n",
       "      <td>0.714574</td>\n",
       "      <td>0.990331</td>\n",
       "      <td>0.916603</td>\n",
       "      <td>0.801865</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.642988</td>\n",
       "      <td>0.998385</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>42101</td>\n",
       "      <td>757.499</td>\n",
       "      <td>281.576392</td>\n",
       "      <td>190.713136</td>\n",
       "      <td>1.476439</td>\n",
       "      <td>0.735702</td>\n",
       "      <td>42494</td>\n",
       "      <td>231.526798</td>\n",
       "      <td>0.799943</td>\n",
       "      <td>0.990752</td>\n",
       "      <td>0.922015</td>\n",
       "      <td>0.822252</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.676099</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>42139</td>\n",
       "      <td>759.321</td>\n",
       "      <td>281.539928</td>\n",
       "      <td>191.187979</td>\n",
       "      <td>1.472582</td>\n",
       "      <td>0.734065</td>\n",
       "      <td>42569</td>\n",
       "      <td>231.631261</td>\n",
       "      <td>0.729932</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.918424</td>\n",
       "      <td>0.822730</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.676884</td>\n",
       "      <td>0.996767</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>42147</td>\n",
       "      <td>763.779</td>\n",
       "      <td>283.382636</td>\n",
       "      <td>190.275731</td>\n",
       "      <td>1.489326</td>\n",
       "      <td>0.741055</td>\n",
       "      <td>42667</td>\n",
       "      <td>231.653248</td>\n",
       "      <td>0.705389</td>\n",
       "      <td>0.987813</td>\n",
       "      <td>0.907906</td>\n",
       "      <td>0.817457</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.668237</td>\n",
       "      <td>0.995222</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>42159</td>\n",
       "      <td>772.237</td>\n",
       "      <td>295.142741</td>\n",
       "      <td>182.204716</td>\n",
       "      <td>1.619841</td>\n",
       "      <td>0.786693</td>\n",
       "      <td>42600</td>\n",
       "      <td>231.686223</td>\n",
       "      <td>0.788962</td>\n",
       "      <td>0.989648</td>\n",
       "      <td>0.888380</td>\n",
       "      <td>0.784997</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.998180</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13611 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0      28395    610.291       208.178117       173.888747      1.197191   \n",
       "1      28734    638.018       200.524796       182.734419      1.097356   \n",
       "2      29380    624.110       212.826130       175.931143      1.209713   \n",
       "3      30008    645.884       210.557999       182.516516      1.153638   \n",
       "4      30140    620.134       201.847882       190.279279      1.060798   \n",
       "...      ...        ...              ...              ...           ...   \n",
       "13606  42097    759.696       288.721612       185.944705      1.552728   \n",
       "13607  42101    757.499       281.576392       190.713136      1.476439   \n",
       "13608  42139    759.321       281.539928       191.187979      1.472582   \n",
       "13609  42147    763.779       283.382636       190.275731      1.489326   \n",
       "13610  42159    772.237       295.142741       182.204716      1.619841   \n",
       "\n",
       "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0          0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
       "1          0.411785       29172     191.272750  0.783968  0.984986   0.887034   \n",
       "2          0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
       "3          0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
       "4          0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
       "...             ...         ...            ...       ...       ...        ...   \n",
       "13606      0.765002       42508     231.515799  0.714574  0.990331   0.916603   \n",
       "13607      0.735702       42494     231.526798  0.799943  0.990752   0.922015   \n",
       "13608      0.734065       42569     231.631261  0.729932  0.989899   0.918424   \n",
       "13609      0.741055       42667     231.653248  0.705389  0.987813   0.907906   \n",
       "13610      0.786693       42600     231.686223  0.788962  0.989648   0.888380   \n",
       "\n",
       "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
       "0         0.913358      0.007332      0.003147      0.834222      0.998724   \n",
       "1         0.953861      0.006979      0.003564      0.909851      0.998430   \n",
       "2         0.908774      0.007244      0.003048      0.825871      0.999066   \n",
       "3         0.928329      0.007017      0.003215      0.861794      0.994199   \n",
       "4         0.970516      0.006697      0.003665      0.941900      0.999166   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "13606     0.801865      0.006858      0.001749      0.642988      0.998385   \n",
       "13607     0.822252      0.006688      0.001886      0.676099      0.998219   \n",
       "13608     0.822730      0.006681      0.001888      0.676884      0.996767   \n",
       "13609     0.817457      0.006724      0.001852      0.668237      0.995222   \n",
       "13610     0.784997      0.007001      0.001640      0.616221      0.998180   \n",
       "\n",
       "          Class  \n",
       "0         SEKER  \n",
       "1         SEKER  \n",
       "2         SEKER  \n",
       "3         SEKER  \n",
       "4         SEKER  \n",
       "...         ...  \n",
       "13606  DERMASON  \n",
       "13607  DERMASON  \n",
       "13608  DERMASON  \n",
       "13609  DERMASON  \n",
       "13610  DERMASON  \n",
       "\n",
       "[13611 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DryBeanData = pd.read_excel('/kaggle/input/dry-bean-dataset/Dry_Bean_Dataset/Dry_Bean_Dataset.xlsx')\n",
    "DryBeanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ec15b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:33:01.941260Z",
     "iopub.status.busy": "2022-05-06T02:33:01.940962Z",
     "iopub.status.idle": "2022-05-06T02:33:01.949068Z",
     "shell.execute_reply": "2022-05-06T02:33:01.948418Z"
    },
    "papermill": {
     "duration": 0.091446,
     "end_time": "2022-05-06T02:33:01.951466",
     "exception": false,
     "start_time": "2022-05-06T02:33:01.860020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictForClasses = {k:v for k, v in zip(list(set(DryBeanData.iloc[:, -1].tolist())),\n",
    "                                     list(range(len(list(set(DryBeanData.iloc[:, -1].tolist()))))))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed054f1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:33:02.114004Z",
     "iopub.status.busy": "2022-05-06T02:33:02.113749Z",
     "iopub.status.idle": "2022-05-06T02:33:02.119413Z",
     "shell.execute_reply": "2022-05-06T02:33:02.118823Z"
    },
    "papermill": {
     "duration": 0.091409,
     "end_time": "2022-05-06T02:33:02.124035",
     "exception": false,
     "start_time": "2022-05-06T02:33:02.032626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SIRA': 0,\n",
       " 'BARBUNYA': 1,\n",
       " 'HOROZ': 2,\n",
       " 'BOMBAY': 3,\n",
       " 'DERMASON': 4,\n",
       " 'CALI': 5,\n",
       " 'SEKER': 6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictForClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd53c717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:33:02.285920Z",
     "iopub.status.busy": "2022-05-06T02:33:02.285657Z",
     "iopub.status.idle": "2022-05-06T02:33:07.485814Z",
     "shell.execute_reply": "2022-05-06T02:33:07.485078Z"
    },
    "papermill": {
     "duration": 5.282536,
     "end_time": "2022-05-06T02:33:07.487818",
     "exception": false,
     "start_time": "2022-05-06T02:33:02.205282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(13611):\n",
    "    DryBeanData.loc[i, 'Class'] = dictForClasses[DryBeanData.loc[i, 'Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fa5174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:33:07.587991Z",
     "iopub.status.busy": "2022-05-06T02:33:07.587289Z",
     "iopub.status.idle": "2022-05-06T02:33:07.611103Z",
     "shell.execute_reply": "2022-05-06T02:33:07.610455Z"
    },
    "papermill": {
     "duration": 0.075041,
     "end_time": "2022-05-06T02:33:07.612717",
     "exception": false,
     "start_time": "2022-05-06T02:33:07.537676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28395</td>\n",
       "      <td>610.291</td>\n",
       "      <td>208.178117</td>\n",
       "      <td>173.888747</td>\n",
       "      <td>1.197191</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.141097</td>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28734</td>\n",
       "      <td>638.018</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.272750</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29380</td>\n",
       "      <td>624.110</td>\n",
       "      <td>212.826130</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30008</td>\n",
       "      <td>645.884</td>\n",
       "      <td>210.557999</td>\n",
       "      <td>182.516516</td>\n",
       "      <td>1.153638</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.467062</td>\n",
       "      <td>0.782681</td>\n",
       "      <td>0.976696</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30140</td>\n",
       "      <td>620.134</td>\n",
       "      <td>201.847882</td>\n",
       "      <td>190.279279</td>\n",
       "      <td>1.060798</td>\n",
       "      <td>0.333680</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.896503</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13606</th>\n",
       "      <td>42097</td>\n",
       "      <td>759.696</td>\n",
       "      <td>288.721612</td>\n",
       "      <td>185.944705</td>\n",
       "      <td>1.552728</td>\n",
       "      <td>0.765002</td>\n",
       "      <td>42508</td>\n",
       "      <td>231.515799</td>\n",
       "      <td>0.714574</td>\n",
       "      <td>0.990331</td>\n",
       "      <td>0.916603</td>\n",
       "      <td>0.801865</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.642988</td>\n",
       "      <td>0.998385</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>42101</td>\n",
       "      <td>757.499</td>\n",
       "      <td>281.576392</td>\n",
       "      <td>190.713136</td>\n",
       "      <td>1.476439</td>\n",
       "      <td>0.735702</td>\n",
       "      <td>42494</td>\n",
       "      <td>231.526798</td>\n",
       "      <td>0.799943</td>\n",
       "      <td>0.990752</td>\n",
       "      <td>0.922015</td>\n",
       "      <td>0.822252</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.676099</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>42139</td>\n",
       "      <td>759.321</td>\n",
       "      <td>281.539928</td>\n",
       "      <td>191.187979</td>\n",
       "      <td>1.472582</td>\n",
       "      <td>0.734065</td>\n",
       "      <td>42569</td>\n",
       "      <td>231.631261</td>\n",
       "      <td>0.729932</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.918424</td>\n",
       "      <td>0.822730</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.676884</td>\n",
       "      <td>0.996767</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>42147</td>\n",
       "      <td>763.779</td>\n",
       "      <td>283.382636</td>\n",
       "      <td>190.275731</td>\n",
       "      <td>1.489326</td>\n",
       "      <td>0.741055</td>\n",
       "      <td>42667</td>\n",
       "      <td>231.653248</td>\n",
       "      <td>0.705389</td>\n",
       "      <td>0.987813</td>\n",
       "      <td>0.907906</td>\n",
       "      <td>0.817457</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.668237</td>\n",
       "      <td>0.995222</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>42159</td>\n",
       "      <td>772.237</td>\n",
       "      <td>295.142741</td>\n",
       "      <td>182.204716</td>\n",
       "      <td>1.619841</td>\n",
       "      <td>0.786693</td>\n",
       "      <td>42600</td>\n",
       "      <td>231.686223</td>\n",
       "      <td>0.788962</td>\n",
       "      <td>0.989648</td>\n",
       "      <td>0.888380</td>\n",
       "      <td>0.784997</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.998180</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13611 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0      28395    610.291       208.178117       173.888747      1.197191   \n",
       "1      28734    638.018       200.524796       182.734419      1.097356   \n",
       "2      29380    624.110       212.826130       175.931143      1.209713   \n",
       "3      30008    645.884       210.557999       182.516516      1.153638   \n",
       "4      30140    620.134       201.847882       190.279279      1.060798   \n",
       "...      ...        ...              ...              ...           ...   \n",
       "13606  42097    759.696       288.721612       185.944705      1.552728   \n",
       "13607  42101    757.499       281.576392       190.713136      1.476439   \n",
       "13608  42139    759.321       281.539928       191.187979      1.472582   \n",
       "13609  42147    763.779       283.382636       190.275731      1.489326   \n",
       "13610  42159    772.237       295.142741       182.204716      1.619841   \n",
       "\n",
       "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0          0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
       "1          0.411785       29172     191.272750  0.783968  0.984986   0.887034   \n",
       "2          0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
       "3          0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
       "4          0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
       "...             ...         ...            ...       ...       ...        ...   \n",
       "13606      0.765002       42508     231.515799  0.714574  0.990331   0.916603   \n",
       "13607      0.735702       42494     231.526798  0.799943  0.990752   0.922015   \n",
       "13608      0.734065       42569     231.631261  0.729932  0.989899   0.918424   \n",
       "13609      0.741055       42667     231.653248  0.705389  0.987813   0.907906   \n",
       "13610      0.786693       42600     231.686223  0.788962  0.989648   0.888380   \n",
       "\n",
       "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
       "0         0.913358      0.007332      0.003147      0.834222      0.998724   \n",
       "1         0.953861      0.006979      0.003564      0.909851      0.998430   \n",
       "2         0.908774      0.007244      0.003048      0.825871      0.999066   \n",
       "3         0.928329      0.007017      0.003215      0.861794      0.994199   \n",
       "4         0.970516      0.006697      0.003665      0.941900      0.999166   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "13606     0.801865      0.006858      0.001749      0.642988      0.998385   \n",
       "13607     0.822252      0.006688      0.001886      0.676099      0.998219   \n",
       "13608     0.822730      0.006681      0.001888      0.676884      0.996767   \n",
       "13609     0.817457      0.006724      0.001852      0.668237      0.995222   \n",
       "13610     0.784997      0.007001      0.001640      0.616221      0.998180   \n",
       "\n",
       "      Class  \n",
       "0         6  \n",
       "1         6  \n",
       "2         6  \n",
       "3         6  \n",
       "4         6  \n",
       "...     ...  \n",
       "13606     4  \n",
       "13607     4  \n",
       "13608     4  \n",
       "13609     4  \n",
       "13610     4  \n",
       "\n",
       "[13611 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DryBeanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee706a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:33:07.713998Z",
     "iopub.status.busy": "2022-05-06T02:33:07.713359Z",
     "iopub.status.idle": "2022-05-06T02:33:07.720927Z",
     "shell.execute_reply": "2022-05-06T02:33:07.720258Z"
    },
    "papermill": {
     "duration": 0.059422,
     "end_time": "2022-05-06T02:33:07.722545",
     "exception": false,
     "start_time": "2022-05-06T02:33:07.663123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.array(DryBeanData.iloc[:, 0:16])\n",
    "y = np.asarray(DryBeanData.iloc[:, -1]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54394414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:33:07.822691Z",
     "iopub.status.busy": "2022-05-06T02:33:07.822464Z",
     "iopub.status.idle": "2022-05-06T02:33:19.697654Z",
     "shell.execute_reply": "2022-05-06T02:33:19.696342Z"
    },
    "papermill": {
     "duration": 11.927765,
     "end_time": "2022-05-06T02:33:19.699997",
     "exception": false,
     "start_time": "2022-05-06T02:33:07.772232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 05-06 02:33:07] {2105} INFO - task = classification\n",
      "[flaml.automl: 05-06 02:33:07] {2107} INFO - Data split method: stratified\n",
      "[flaml.automl: 05-06 02:33:07] {2111} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-06 02:33:07] {2188} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl: 05-06 02:33:08] {2281} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl: 05-06 02:33:08] {2567} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:08] {2698} INFO - Estimated sufficient time budget=1274s. Estimated necessary time budget=31s.\n",
      "[flaml.automl: 05-06 02:33:08] {2750} INFO -  at 0.3s,\testimator lgbm's best error=0.1284,\tbest estimator lgbm's best error=0.1284\n",
      "[flaml.automl: 05-06 02:33:08] {2567} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:08] {2750} INFO -  at 0.4s,\testimator lgbm's best error=0.1284,\tbest estimator lgbm's best error=0.1284\n",
      "[flaml.automl: 05-06 02:33:08] {2567} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:08] {2750} INFO -  at 0.4s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
      "[flaml.automl: 05-06 02:33:08] {2567} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:08] {2750} INFO -  at 0.5s,\testimator lgbm's best error=0.1012,\tbest estimator lgbm's best error=0.1012\n",
      "[flaml.automl: 05-06 02:33:08] {2567} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:08] {2750} INFO -  at 0.6s,\testimator lgbm's best error=0.1012,\tbest estimator lgbm's best error=0.1012\n",
      "[flaml.automl: 05-06 02:33:08] {2567} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:08] {2750} INFO -  at 0.8s,\testimator lgbm's best error=0.0963,\tbest estimator lgbm's best error=0.0963\n",
      "[flaml.automl: 05-06 02:33:08] {2567} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl: 05-06 02:33:08] {2750} INFO -  at 0.8s,\testimator xgboost's best error=0.1313,\tbest estimator lgbm's best error=0.0963\n",
      "[flaml.automl: 05-06 02:33:08] {2567} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:08] {2750} INFO -  at 0.9s,\testimator lgbm's best error=0.0963,\tbest estimator lgbm's best error=0.0963\n",
      "[flaml.automl: 05-06 02:33:08] {2567} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:09] {2750} INFO -  at 1.2s,\testimator lgbm's best error=0.0778,\tbest estimator lgbm's best error=0.0778\n",
      "[flaml.automl: 05-06 02:33:09] {2567} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 05-06 02:33:09] {2750} INFO -  at 1.3s,\testimator xgboost's best error=0.1313,\tbest estimator lgbm's best error=0.0778\n",
      "[flaml.automl: 05-06 02:33:09] {2567} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 05-06 02:33:09] {2750} INFO -  at 1.4s,\testimator xgboost's best error=0.1167,\tbest estimator lgbm's best error=0.0778\n",
      "[flaml.automl: 05-06 02:33:09] {2567} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl: 05-06 02:33:09] {2750} INFO -  at 1.7s,\testimator extra_tree's best error=0.2354,\tbest estimator lgbm's best error=0.0778\n",
      "[flaml.automl: 05-06 02:33:09] {2567} INFO - iteration 12, current learner rf\n",
      "[flaml.automl: 05-06 02:33:09] {2750} INFO -  at 2.1s,\testimator rf's best error=0.2617,\tbest estimator lgbm's best error=0.0778\n",
      "[flaml.automl: 05-06 02:33:09] {2567} INFO - iteration 13, current learner rf\n",
      "[flaml.automl: 05-06 02:33:10] {2750} INFO -  at 2.4s,\testimator rf's best error=0.1284,\tbest estimator lgbm's best error=0.0778\n",
      "[flaml.automl: 05-06 02:33:10] {2567} INFO - iteration 14, current learner rf\n",
      "[flaml.automl: 05-06 02:33:10] {2750} INFO -  at 2.7s,\testimator rf's best error=0.1284,\tbest estimator lgbm's best error=0.0778\n",
      "[flaml.automl: 05-06 02:33:10] {2567} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 05-06 02:33:10] {2750} INFO -  at 2.8s,\testimator xgboost's best error=0.1031,\tbest estimator lgbm's best error=0.0778\n",
      "[flaml.automl: 05-06 02:33:10] {2567} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:10] {2750} INFO -  at 2.9s,\testimator lgbm's best error=0.0778,\tbest estimator lgbm's best error=0.0778\n",
      "[flaml.automl: 05-06 02:33:10] {2567} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-06 02:33:11] {2750} INFO -  at 3.2s,\testimator extra_tree's best error=0.1420,\tbest estimator lgbm's best error=0.0778\n",
      "[flaml.automl: 05-06 02:33:11] {2567} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:12] {2750} INFO -  at 5.1s,\testimator lgbm's best error=0.0681,\tbest estimator lgbm's best error=0.0681\n",
      "[flaml.automl: 05-06 02:33:12] {2567} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 05-06 02:33:13] {2750} INFO -  at 5.3s,\testimator xgboost's best error=0.1012,\tbest estimator lgbm's best error=0.0681\n",
      "[flaml.automl: 05-06 02:33:13] {2567} INFO - iteration 20, current learner rf\n",
      "[flaml.automl: 05-06 02:33:13] {2750} INFO -  at 5.7s,\testimator rf's best error=0.1284,\tbest estimator lgbm's best error=0.0681\n",
      "[flaml.automl: 05-06 02:33:13] {2567} INFO - iteration 21, current learner extra_tree\n",
      "[flaml.automl: 05-06 02:33:13] {2750} INFO -  at 6.1s,\testimator extra_tree's best error=0.1420,\tbest estimator lgbm's best error=0.0681\n",
      "[flaml.automl: 05-06 02:33:13] {2567} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 05-06 02:33:16] {2750} INFO -  at 8.4s,\testimator lgbm's best error=0.0681,\tbest estimator lgbm's best error=0.0681\n",
      "[flaml.automl: 05-06 02:33:16] {2567} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 05-06 02:33:16] {2750} INFO -  at 8.7s,\testimator rf's best error=0.1284,\tbest estimator lgbm's best error=0.0681\n",
      "[flaml.automl: 05-06 02:33:16] {2567} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 05-06 02:33:16] {2750} INFO -  at 9.2s,\testimator extra_tree's best error=0.1420,\tbest estimator lgbm's best error=0.0681\n",
      "[flaml.automl: 05-06 02:33:16] {2567} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 05-06 02:33:17] {2750} INFO -  at 9.5s,\testimator extra_tree's best error=0.1420,\tbest estimator lgbm's best error=0.0681\n",
      "[flaml.automl: 05-06 02:33:17] {2567} INFO - iteration 26, current learner rf\n",
      "[flaml.automl: 05-06 02:33:17] {2750} INFO -  at 9.8s,\testimator rf's best error=0.1284,\tbest estimator lgbm's best error=0.0681\n",
      "[flaml.automl: 05-06 02:33:17] {2567} INFO - iteration 27, current learner catboost\n",
      "[flaml.automl: 05-06 02:33:17] {2750} INFO -  at 10.0s,\testimator catboost's best error=0.1897,\tbest estimator lgbm's best error=0.0681\n",
      "[flaml.automl: 05-06 02:33:19] {2976} INFO - retrain lgbm for 1.8s\n",
      "[flaml.automl: 05-06 02:33:19] {2981} INFO - retrained model: LGBMClassifier(colsample_bytree=0.8345075630938922,\n",
      "               learning_rate=0.15922418945050276, max_bin=1023,\n",
      "               min_child_samples=9, n_estimators=83, num_leaves=16,\n",
      "               reg_alpha=0.0009765625, reg_lambda=1.6702305601383631,\n",
      "               verbose=-1)\n",
      "[flaml.automl: 05-06 02:33:19] {2310} INFO - fit succeeded\n",
      "[flaml.automl: 05-06 02:33:19] {2312} INFO - Time taken to find the best model: 5.115077257156372\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2022)\n",
    "\n",
    "model = AutoML()\n",
    "model.fit(X_train, y_train, task='classification', metric='accuracy', time_budget=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4be4207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:33:19.841281Z",
     "iopub.status.busy": "2022-05-06T02:33:19.840506Z",
     "iopub.status.idle": "2022-05-06T02:33:19.848538Z",
     "shell.execute_reply": "2022-05-06T02:33:19.847479Z"
    },
    "papermill": {
     "duration": 0.080631,
     "end_time": "2022-05-06T02:33:19.850214",
     "exception": false,
     "start_time": "2022-05-06T02:33:19.769583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ML Model: lgbm\n",
      "Best hyperparmeter config: {'n_estimators': 83, 'num_leaves': 16, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 10, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6702305601383631}\n",
      "Best accuracy on validation data: 0.931907\n",
      "Training duration of best run: 1.810215 s\n"
     ]
    }
   ],
   "source": [
    "print('Best ML Model:', model.best_estimator)\n",
    "print('Best hyperparmeter config:', model.best_config)\n",
    "print('Best accuracy on validation data: %f'%(1 - model.best_loss))\n",
    "print('Training duration of best run: %f s'%(model.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7098cbd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:33:19.990955Z",
     "iopub.status.busy": "2022-05-06T02:33:19.990259Z",
     "iopub.status.idle": "2022-05-06T02:33:53.190214Z",
     "shell.execute_reply": "2022-05-06T02:33:53.189505Z"
    },
    "papermill": {
     "duration": 33.272485,
     "end_time": "2022-05-06T02:33:53.191954",
     "exception": false,
     "start_time": "2022-05-06T02:33:19.919469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 02:33:20.864960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 02:33:20.870032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 02:33:20.870758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 02:33:20.871906: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-06 02:33:20.872162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 02:33:20.872838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 02:33:20.873450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 02:33:24.434561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 02:33:24.435452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 02:33:24.436189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 02:33:24.437638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15219 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-05-06 02:33:24.842369: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "213/213 [==============================] - 2s 4ms/step - loss: 0.8109 - sparse_categorical_accuracy: 0.7692\n",
      "Epoch 2/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.4650 - sparse_categorical_accuracy: 0.8655\n",
      "Epoch 3/50\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.4048 - sparse_categorical_accuracy: 0.8804\n",
      "Epoch 4/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3804 - sparse_categorical_accuracy: 0.8841\n",
      "Epoch 5/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3683 - sparse_categorical_accuracy: 0.8844\n",
      "Epoch 6/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3514 - sparse_categorical_accuracy: 0.8887\n",
      "Epoch 7/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3473 - sparse_categorical_accuracy: 0.8869\n",
      "Epoch 8/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3422 - sparse_categorical_accuracy: 0.8907\n",
      "Epoch 9/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3272 - sparse_categorical_accuracy: 0.8924\n",
      "Epoch 10/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3353 - sparse_categorical_accuracy: 0.8901\n",
      "Epoch 11/50\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.3196 - sparse_categorical_accuracy: 0.8962\n",
      "Epoch 12/50\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.3110 - sparse_categorical_accuracy: 0.8976\n",
      "Epoch 13/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3202 - sparse_categorical_accuracy: 0.8946\n",
      "Epoch 14/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3012 - sparse_categorical_accuracy: 0.8985\n",
      "Epoch 15/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3140 - sparse_categorical_accuracy: 0.8957\n",
      "Epoch 16/50\n",
      "213/213 [==============================] - 1s 4ms/step - loss: 0.3009 - sparse_categorical_accuracy: 0.8983\n",
      "Epoch 17/50\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.3048 - sparse_categorical_accuracy: 0.8976\n",
      "Epoch 18/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2900 - sparse_categorical_accuracy: 0.9032\n",
      "Epoch 19/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.3084 - sparse_categorical_accuracy: 0.8967\n",
      "Epoch 20/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2907 - sparse_categorical_accuracy: 0.9033\n",
      "Epoch 21/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2867 - sparse_categorical_accuracy: 0.9003\n",
      "Epoch 22/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2952 - sparse_categorical_accuracy: 0.9008\n",
      "Epoch 23/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2906 - sparse_categorical_accuracy: 0.9002\n",
      "Epoch 24/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3025 - sparse_categorical_accuracy: 0.8960\n",
      "Epoch 25/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2993 - sparse_categorical_accuracy: 0.8977\n",
      "Epoch 26/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2836 - sparse_categorical_accuracy: 0.9044\n",
      "Epoch 27/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2768 - sparse_categorical_accuracy: 0.9053\n",
      "Epoch 28/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2854 - sparse_categorical_accuracy: 0.9039\n",
      "Epoch 29/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2730 - sparse_categorical_accuracy: 0.9075\n",
      "Epoch 30/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2762 - sparse_categorical_accuracy: 0.9041\n",
      "Epoch 31/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2912 - sparse_categorical_accuracy: 0.9004\n",
      "Epoch 32/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2861 - sparse_categorical_accuracy: 0.9006\n",
      "Epoch 33/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2910 - sparse_categorical_accuracy: 0.9011\n",
      "Epoch 34/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2815 - sparse_categorical_accuracy: 0.9019\n",
      "Epoch 35/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2902 - sparse_categorical_accuracy: 0.9006\n",
      "Epoch 36/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2753 - sparse_categorical_accuracy: 0.9058\n",
      "Epoch 37/50\n",
      "213/213 [==============================] - 1s 4ms/step - loss: 0.2783 - sparse_categorical_accuracy: 0.9049\n",
      "Epoch 38/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2794 - sparse_categorical_accuracy: 0.9041\n",
      "Epoch 39/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2771 - sparse_categorical_accuracy: 0.9041\n",
      "Epoch 40/50\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.2772 - sparse_categorical_accuracy: 0.9036\n",
      "Epoch 41/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2772 - sparse_categorical_accuracy: 0.9059\n",
      "Epoch 42/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2778 - sparse_categorical_accuracy: 0.9055\n",
      "Epoch 43/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2802 - sparse_categorical_accuracy: 0.9035\n",
      "Epoch 44/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2673 - sparse_categorical_accuracy: 0.9065\n",
      "Epoch 45/50\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.2717 - sparse_categorical_accuracy: 0.9053\n",
      "Epoch 46/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2741 - sparse_categorical_accuracy: 0.9061\n",
      "Epoch 47/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2687 - sparse_categorical_accuracy: 0.9058\n",
      "Epoch 48/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2726 - sparse_categorical_accuracy: 0.9058\n",
      "Epoch 49/50\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.2813 - sparse_categorical_accuracy: 0.9018\n",
      "Epoch 50/50\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2654 - sparse_categorical_accuracy: 0.9097\n",
      "Model: \"bean_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo multiple                  64        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1088      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  903       \n",
      "=================================================================\n",
      "Total params: 10,375\n",
      "Trainable params: 10,343\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "class BeanModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BeanModel, self).__init__()\n",
    "        self.B1 = tf.keras.layers.BatchNormalization()\n",
    "        self.D1 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.Dr1 = tf.keras.layers.Dropout(0.2)\n",
    "        self.D2 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.D3 = tf.keras.layers.Dense(7, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2())\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.B1(x)\n",
    "        x = self.D1(x)\n",
    "        x = self.Dr1(x)\n",
    "        x = self.D2(x)\n",
    "        y = self.D3(x)\n",
    "        return y\n",
    "\n",
    "TFmodel = BeanModel()\n",
    "TFmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "               metrics=['sparse_categorical_accuracy'])\n",
    "history = TFmodel.fit(X, y, batch_size=64, epochs=50)\n",
    "\n",
    "TFmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceb6f699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T02:33:53.692453Z",
     "iopub.status.busy": "2022-05-06T02:33:53.692198Z",
     "iopub.status.idle": "2022-05-06T02:33:53.977605Z",
     "shell.execute_reply": "2022-05-06T02:33:53.976803Z"
    },
    "papermill": {
     "duration": 0.538322,
     "end_time": "2022-05-06T02:33:53.979820",
     "exception": false,
     "start_time": "2022-05-06T02:33:53.441498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainingAcc = history.history['sparse_categorical_accuracy']\n",
    "TrainingLoss = history.history['loss']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Training Accuracy')\n",
    "plt.plot(TrainingAcc)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Training Loss')\n",
    "plt.plot(TrainingLoss)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd013c",
   "metadata": {
    "papermill": {
     "duration": 0.258401,
     "end_time": "2022-05-06T02:33:54.517568",
     "exception": false,
     "start_time": "2022-05-06T02:33:54.259167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 111.354606,
   "end_time": "2022-05-06T02:33:59.337801",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-06T02:32:07.983195",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
